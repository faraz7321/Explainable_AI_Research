{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rescale_score_by_abs (score, max_score, min_score):\n",
    "    # CASE 1: positive AND negative scores occur --------------------\n",
    "    if max_score>0 and min_score<0:\n",
    "    \n",
    "        if max_score >= abs(min_score):   # deepest color is positive\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/max_score)\n",
    "            else:\n",
    "                return 0.5 - 0.5*(abs(score)/max_score)\n",
    "\n",
    "        else:                             # deepest color is negative\n",
    "            if score>=0:\n",
    "                return 0.5 + 0.5*(score/abs(min_score))\n",
    "            else:\n",
    "                return 0.5 - 0.5*(score/min_score)   \n",
    "    \n",
    "    # CASE 2: ONLY positive scores occur -----------------------------       \n",
    "    elif max_score>0 and min_score>=0: \n",
    "        if max_score == min_score:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.5 + 0.5*(score/max_score)\n",
    "    \n",
    "    # CASE 3: ONLY negative scores occur -----------------------------\n",
    "    elif max_score<=0 and min_score<0: \n",
    "        if max_score == min_score:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 0.5 - 0.5*(score/min_score)    \n",
    "  \n",
    "      \n",
    "def getRGB (c_tuple):\n",
    "    return \"#%02x%02x%02x\"%(int(c_tuple[0]*255), int(c_tuple[1]*255), int(c_tuple[2]*255))\n",
    "\n",
    "     \n",
    "def span_word (word, score, colormap):\n",
    "    return \"<span style=\\\"background-color:\"+getRGB(colormap(score))+\"\\\">\"+word+\"</span>\"\n",
    "\n",
    "\n",
    "def html_heatmap (words, scores, cmap_name=\"bwr\"):\n",
    "    colormap  = plt.get_cmap(cmap_name)\n",
    "     \n",
    "    assert len(words)==len(scores)\n",
    "    max_s     = max(scores)\n",
    "    min_s     = min(scores)\n",
    "    \n",
    "    output_text = \"\"\n",
    "    \n",
    "    for idx, w in enumerate(words):\n",
    "        score       = rescale_score_by_abs(scores[idx], max_s, min_s)\n",
    "        output_text = output_text + span_word(w, score, colormap) + \" \"\n",
    "    \n",
    "    return output_text + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import newaxis as na\n",
    "\n",
    "\n",
    "def lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor=0.0, debug=False):\n",
    "    sign_out = np.where(hout[na,:]>=0, 1., -1.) # shape (1, M)\n",
    "    \n",
    "    numer    = (w * hin[:,na]) + ( bias_factor * (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units ) # shape (D, M)\n",
    "    # Note: here we multiply the bias_factor with both the bias b and the stabilizer eps since in fact\n",
    "    # using the term (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units in the numerator is only useful for sanity check\n",
    "    # (in the initial paper version we were using (bias_factor*b[na,:]*1. + eps*sign_out*1.) / bias_nb_units instead)\n",
    "    \n",
    "    denom    = hout[na,:] + (eps*sign_out*1.)   # shape (1, M)\n",
    "    \n",
    "    message  = (numer/denom) * Rout[na,:]       # shape (D, M)\n",
    "    \n",
    "    Rin      = message.sum(axis=1)              # shape (D,)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"local diff: \", Rout.sum() - Rin.sum())\n",
    "    # Note: \n",
    "    # - local  layer   relevance conservation if bias_factor==1.0 and bias_nb_units==D (i.e. when only one incoming layer)\n",
    "    # - global network relevance conservation if bias_factor==1.0 and bias_nb_units set accordingly to the total number of lower-layer connections \n",
    "    # -> can be used for sanity check\n",
    "    \n",
    "    return Rin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import newaxis as na\n",
    "#from code.LSTM.LRP_linear_layer import *\n",
    "\n",
    "\n",
    "class LSTM_bidi:\n",
    "    \n",
    "    def __init__(self, model_path='./model/'):\n",
    "   \n",
    "        # vocabulary\n",
    "        f_voc     = open(model_path + \"vocab\", 'rb')\n",
    "        self.voc  = pickle.load(f_voc)\n",
    "        f_voc.close()\n",
    "        \n",
    "        # word embeddings\n",
    "        self.E    = np.load(model_path + 'embeddings.npy', mmap_mode='r') # shape V*e\n",
    "        \n",
    "        # model weights\n",
    "        f_model   = open(model_path + 'model', 'rb')\n",
    "        model     = pickle.load(f_model)\n",
    "        f_model.close()\n",
    "        # LSTM left encoder\n",
    "        self.Wxh_Left  = model[\"Wxh_Left\"]  # shape 4d*e\n",
    "        self.bxh_Left  = model[\"bxh_Left\"]  # shape 4d \n",
    "        self.Whh_Left  = model[\"Whh_Left\"]  # shape 4d*d\n",
    "        self.bhh_Left  = model[\"bhh_Left\"]  # shape 4d  \n",
    "        # LSTM right encoder\n",
    "        self.Wxh_Right = model[\"Wxh_Right\"]\n",
    "        self.bxh_Right = model[\"bxh_Right\"]\n",
    "        self.Whh_Right = model[\"Whh_Right\"]\n",
    "        self.bhh_Right = model[\"bhh_Right\"]   \n",
    "        # linear output layer\n",
    "        self.Why_Left  = model[\"Why_Left\"]  # shape C*d\n",
    "        self.Why_Right = model[\"Why_Right\"] # shape C*d\n",
    "    \n",
    "\n",
    "    def set_input(self, w, delete_pos=None):\n",
    "        T      = len(w)                         # sequence length\n",
    "        d      = int(self.Wxh_Left.shape[0]/4)  # hidden layer dimension\n",
    "        e      = self.E.shape[1]                # word embedding dimension\n",
    "        x      = np.zeros((T, e))\n",
    "        x[:,:] = self.E[w,:]\n",
    "        if delete_pos is not None:\n",
    "            x[delete_pos, :] = np.zeros((len(delete_pos), e))\n",
    "        \n",
    "        self.w              = w\n",
    "        self.x              = x\n",
    "        self.x_rev          = x[::-1,:].copy()\n",
    "        \n",
    "        self.h_Left         = np.zeros((T+1, d))\n",
    "        self.c_Left         = np.zeros((T+1, d))\n",
    "        self.h_Right        = np.zeros((T+1, d))\n",
    "        self.c_Right        = np.zeros((T+1, d))\n",
    "     \n",
    "   \n",
    "    def forward(self):\n",
    "\n",
    "        T      = len(self.w)                         \n",
    "        d      = int(self.Wxh_Left.shape[0]/4) \n",
    "        # gate indices (assuming the gate ordering in the LSTM weights is i,g,f,o):     \n",
    "        idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n",
    "        idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n",
    "          \n",
    "        # initialize\n",
    "        self.gates_xh_Left  = np.zeros((T, 4*d))  \n",
    "        self.gates_hh_Left  = np.zeros((T, 4*d)) \n",
    "        self.gates_pre_Left = np.zeros((T, 4*d))  # gates pre-activation\n",
    "        self.gates_Left     = np.zeros((T, 4*d))  # gates activation\n",
    "        \n",
    "        self.gates_xh_Right = np.zeros((T, 4*d))  \n",
    "        self.gates_hh_Right = np.zeros((T, 4*d)) \n",
    "        self.gates_pre_Right= np.zeros((T, 4*d))\n",
    "        self.gates_Right    = np.zeros((T, 4*d)) \n",
    "             \n",
    "        for t in range(T): \n",
    "            self.gates_xh_Left[t]     = np.dot(self.Wxh_Left, self.x[t])        \n",
    "            self.gates_hh_Left[t]     = np.dot(self.Whh_Left, self.h_Left[t-1]) \n",
    "            self.gates_pre_Left[t]    = self.gates_xh_Left[t] + self.gates_hh_Left[t] + self.bxh_Left + self.bhh_Left\n",
    "            self.gates_Left[t,idx]    = 1.0/(1.0 + np.exp(- self.gates_pre_Left[t,idx]))\n",
    "            self.gates_Left[t,idx_g]  = np.tanh(self.gates_pre_Left[t,idx_g]) \n",
    "            self.c_Left[t]            = self.gates_Left[t,idx_f]*self.c_Left[t-1] + self.gates_Left[t,idx_i]*self.gates_Left[t,idx_g]\n",
    "            self.h_Left[t]            = self.gates_Left[t,idx_o]*np.tanh(self.c_Left[t])\n",
    "            \n",
    "            self.gates_xh_Right[t]    = np.dot(self.Wxh_Right, self.x_rev[t])     \n",
    "            self.gates_hh_Right[t]    = np.dot(self.Whh_Right, self.h_Right[t-1])\n",
    "            self.gates_pre_Right[t]   = self.gates_xh_Right[t] + self.gates_hh_Right[t] + self.bxh_Right + self.bhh_Right\n",
    "            self.gates_Right[t,idx]   = 1.0/(1.0 + np.exp(- self.gates_pre_Right[t,idx]))\n",
    "            self.gates_Right[t,idx_g] = np.tanh(self.gates_pre_Right[t,idx_g])                 \n",
    "            self.c_Right[t]           = self.gates_Right[t,idx_f]*self.c_Right[t-1] + self.gates_Right[t,idx_i]*self.gates_Right[t,idx_g]\n",
    "            self.h_Right[t]           = self.gates_Right[t,idx_o]*np.tanh(self.c_Right[t])\n",
    "            \n",
    "        self.y_Left  = np.dot(self.Why_Left,  self.h_Left[T-1])\n",
    "        self.y_Right = np.dot(self.Why_Right, self.h_Right[T-1])\n",
    "        self.s       = self.y_Left + self.y_Right\n",
    "        \n",
    "        return self.s.copy() # prediction scores\n",
    "     \n",
    "              \n",
    "    def backward(self, w, sensitivity_class):\n",
    "\n",
    "        # forward pass\n",
    "        self.set_input(w)\n",
    "        self.forward() \n",
    "        \n",
    "        T      = len(self.w)\n",
    "        d      = int(self.Wxh_Left.shape[0]/4)\n",
    "        C      = self.Why_Left.shape[0]   # number of classes\n",
    "        idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n",
    "        idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n",
    "        \n",
    "        # initialize\n",
    "        self.dx               = np.zeros(self.x.shape)\n",
    "        self.dx_rev           = np.zeros(self.x.shape)\n",
    "        \n",
    "        self.dh_Left          = np.zeros((T+1, d))\n",
    "        self.dc_Left          = np.zeros((T+1, d))\n",
    "        self.dgates_pre_Left  = np.zeros((T, 4*d))  # gates pre-activation\n",
    "        self.dgates_Left      = np.zeros((T, 4*d))  # gates activation\n",
    "        \n",
    "        self.dh_Right         = np.zeros((T+1, d))\n",
    "        self.dc_Right         = np.zeros((T+1, d))\n",
    "        self.dgates_pre_Right = np.zeros((T, 4*d)) \n",
    "        self.dgates_Right     = np.zeros((T, 4*d))  \n",
    "               \n",
    "        ds                    = np.zeros((C))\n",
    "        ds[sensitivity_class] = 1.0\n",
    "        dy_Left               = ds.copy()\n",
    "        dy_Right              = ds.copy()\n",
    "        \n",
    "        self.dh_Left[T-1]     = np.dot(self.Why_Left.T,  dy_Left)\n",
    "        self.dh_Right[T-1]    = np.dot(self.Why_Right.T, dy_Right)\n",
    "        \n",
    "        for t in reversed(range(T)): \n",
    "            self.dgates_Left[t,idx_o]    = self.dh_Left[t] * np.tanh(self.c_Left[t])  # do[t]\n",
    "            self.dc_Left[t]             += self.dh_Left[t] * self.gates_Left[t,idx_o] * (1.-(np.tanh(self.c_Left[t]))**2) # dc[t]\n",
    "            self.dgates_Left[t,idx_f]    = self.dc_Left[t] * self.c_Left[t-1]         # df[t]\n",
    "            self.dc_Left[t-1]            = self.dc_Left[t] * self.gates_Left[t,idx_f] # dc[t-1]\n",
    "            self.dgates_Left[t,idx_i]    = self.dc_Left[t] * self.gates_Left[t,idx_g] # di[t]\n",
    "            self.dgates_Left[t,idx_g]    = self.dc_Left[t] * self.gates_Left[t,idx_i] # dg[t]\n",
    "            self.dgates_pre_Left[t,idx]  = self.dgates_Left[t,idx] * self.gates_Left[t,idx] * (1.0 - self.gates_Left[t,idx]) # d ifo pre[t]\n",
    "            self.dgates_pre_Left[t,idx_g]= self.dgates_Left[t,idx_g] *  (1.-(self.gates_Left[t,idx_g])**2) # d g pre[t]\n",
    "            self.dh_Left[t-1]            = np.dot(self.Whh_Left.T, self.dgates_pre_Left[t])\n",
    "            self.dx[t]                   = np.dot(self.Wxh_Left.T, self.dgates_pre_Left[t])\n",
    "            \n",
    "            self.dgates_Right[t,idx_o]    = self.dh_Right[t] * np.tanh(self.c_Right[t])         \n",
    "            self.dc_Right[t]             += self.dh_Right[t] * self.gates_Right[t,idx_o] * (1.-(np.tanh(self.c_Right[t]))**2) \n",
    "            self.dgates_Right[t,idx_f]    = self.dc_Right[t] * self.c_Right[t-1]            \n",
    "            self.dc_Right[t-1]            = self.dc_Right[t] * self.gates_Right[t,idx_f] \n",
    "            self.dgates_Right[t,idx_i]    = self.dc_Right[t] * self.gates_Right[t,idx_g]    \n",
    "            self.dgates_Right[t,idx_g]    = self.dc_Right[t] * self.gates_Right[t,idx_i]      \n",
    "            self.dgates_pre_Right[t,idx]  = self.dgates_Right[t,idx] * self.gates_Right[t,idx] * (1.0 - self.gates_Right[t,idx]) \n",
    "            self.dgates_pre_Right[t,idx_g]= self.dgates_Right[t,idx_g] *  (1.-(self.gates_Right[t,idx_g])**2) \n",
    "            self.dh_Right[t-1]            = np.dot(self.Whh_Right.T, self.dgates_pre_Right[t])\n",
    "            self.dx_rev[t]                = np.dot(self.Wxh_Right.T, self.dgates_pre_Right[t])\n",
    "                    \n",
    "        return self.dx.copy(), self.dx_rev[::-1,:].copy()     \n",
    "    \n",
    "                   \n",
    "    def lrp(self, w, LRP_class, eps=0.001, bias_factor=0.0):\n",
    "\n",
    "        # forward pass\n",
    "        self.set_input(w)\n",
    "        self.forward() \n",
    "        \n",
    "        T      = len(self.w)\n",
    "        d      = int(self.Wxh_Left.shape[0]/4)\n",
    "        e      = self.E.shape[1] \n",
    "        C      = self.Why_Left.shape[0]  # number of classes\n",
    "        idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n",
    "        idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n",
    "        \n",
    "        # initialize\n",
    "        Rx       = np.zeros(self.x.shape)\n",
    "        Rx_rev   = np.zeros(self.x.shape)\n",
    "        \n",
    "        Rh_Left  = np.zeros((T+1, d))\n",
    "        Rc_Left  = np.zeros((T+1, d))\n",
    "        Rg_Left  = np.zeros((T,   d)) # gate g only\n",
    "        Rh_Right = np.zeros((T+1, d))\n",
    "        Rc_Right = np.zeros((T+1, d))\n",
    "        Rg_Right = np.zeros((T,   d)) # gate g only\n",
    "        \n",
    "        Rout_mask            = np.zeros((C))\n",
    "        Rout_mask[LRP_class] = 1.0  \n",
    "        \n",
    "        # format reminder: lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor)\n",
    "        Rh_Left[T-1]  = lrp_linear(self.h_Left[T-1],  self.Why_Left.T , np.zeros((C)), self.s, self.s*Rout_mask, 2*d, eps, bias_factor, debug=False)\n",
    "        Rh_Right[T-1] = lrp_linear(self.h_Right[T-1], self.Why_Right.T, np.zeros((C)), self.s, self.s*Rout_mask, 2*d, eps, bias_factor, debug=False)\n",
    "        \n",
    "        for t in reversed(range(T)):\n",
    "            Rc_Left[t]   += Rh_Left[t]\n",
    "            Rc_Left[t-1]  = lrp_linear(self.gates_Left[t,idx_f]*self.c_Left[t-1],         np.identity(d), np.zeros((d)), self.c_Left[t], Rc_Left[t], 2*d, eps, bias_factor, debug=False)\n",
    "            Rg_Left[t]    = lrp_linear(self.gates_Left[t,idx_i]*self.gates_Left[t,idx_g], np.identity(d), np.zeros((d)), self.c_Left[t], Rc_Left[t], 2*d, eps, bias_factor, debug=False)\n",
    "            Rx[t]         = lrp_linear(self.x[t],        self.Wxh_Left[idx_g].T, self.bxh_Left[idx_g]+self.bhh_Left[idx_g], self.gates_pre_Left[t,idx_g], Rg_Left[t], d+e, eps, bias_factor, debug=False)\n",
    "            Rh_Left[t-1]  = lrp_linear(self.h_Left[t-1], self.Whh_Left[idx_g].T, self.bxh_Left[idx_g]+self.bhh_Left[idx_g], self.gates_pre_Left[t,idx_g], Rg_Left[t], d+e, eps, bias_factor, debug=False)\n",
    "            \n",
    "            Rc_Right[t]  += Rh_Right[t]\n",
    "            Rc_Right[t-1] = lrp_linear(self.gates_Right[t,idx_f]*self.c_Right[t-1],         np.identity(d), np.zeros((d)), self.c_Right[t], Rc_Right[t], 2*d, eps, bias_factor, debug=False)\n",
    "            Rg_Right[t]   = lrp_linear(self.gates_Right[t,idx_i]*self.gates_Right[t,idx_g], np.identity(d), np.zeros((d)), self.c_Right[t], Rc_Right[t], 2*d, eps, bias_factor, debug=False)\n",
    "            Rx_rev[t]     = lrp_linear(self.x_rev[t],     self.Wxh_Right[idx_g].T, self.bxh_Right[idx_g]+self.bhh_Right[idx_g], self.gates_pre_Right[t,idx_g], Rg_Right[t], d+e, eps, bias_factor, debug=False)\n",
    "            Rh_Right[t-1] = lrp_linear(self.h_Right[t-1], self.Whh_Right[idx_g].T, self.bxh_Right[idx_g]+self.bhh_Right[idx_g], self.gates_pre_Right[t,idx_g], Rg_Right[t], d+e, eps, bias_factor, debug=False)\n",
    "                   \n",
    "        return Rx, Rx_rev[::-1,:], Rh_Left[-1].sum()+Rc_Left[-1].sum()+Rh_Right[-1].sum()+Rc_Right[-1].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from code.LSTM.LSTM_bidi import * \n",
    "#from code.util.heatmap import html_heatmap\n",
    "\n",
    "import codecs\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sentence(sent_idx):\n",
    "    idx = 1\n",
    "    with codecs.open(\"./data/sequence_test.txt\", 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line          = line.rstrip('\\n')\n",
    "            line          = line.split('\\t')\n",
    "            true_class    = int(line[0])-1         # true class\n",
    "            words         = line[1].split(' | ')   # sentence as list of words\n",
    "            if idx == sent_idx:\n",
    "                return words, true_class\n",
    "            idx +=1\n",
    "\n",
    "def predict(words):\n",
    "    net                 = LSTM_bidi()                                   # load trained LSTM model\n",
    "    w_indices           = [net.voc.index(w) for w in words]             # convert input sentence to word IDs\n",
    "    net.set_input(w_indices)                                            # set LSTM input sequence\n",
    "    scores              = net.forward()                                 # classification prediction scores\n",
    "    return np.argmax(scores)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, _ = get_test_sentence(291)                                       # SST test set sentence number 291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, uncomment one of the following sentences, or define your own sequence (only words contained in the vocabulary are supported!)\n",
    "#words = ['this','movie','was','actually','neither','that','funny',',','nor','super','witty','.']\n",
    "words = ['this', 'film', 'does', 'n\\'t', 'care', 'about', 'cleverness', ',', 'wit', 'or', 'any', 'other', 'kind', 'of', 'intelligent', 'humor', '.']\n",
    "#words = ['i','hate','the','movie','though','the','plot','is','interesting','.']\n",
    "#words = ['used', 'to', 'be', 'my', 'favorite']\n",
    "#words = ['not', 'worth', 'the', 'time']\n",
    "#words = ['is', 'n\\'t', 'a', 'bad', 'film'] # Note: misclassified sample!\n",
    "#words = ['is', 'n\\'t', 'very', 'interesting'] \n",
    "#words = ['it', '\\'s', 'easy' ,'to' ,'love' ,'robin' ,'tunney' ,'--' ,'she' ,'\\'s' ,'pretty' ,'and' ,'she' ,'can' ,'act' ,'--' ,'but' ,'it' ,'gets' ,'harder' ,'and' ,'harder' ,'to' ,'understand' ,'her' ,'choices', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = predict(words)                                        # get predicted class\n",
    "target_class    = predicted_class                                       # define relevance target class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'film', 'does', \"n't\", 'care', 'about', 'cleverness', ',', 'wit', 'or', 'any', 'other', 'kind', 'of', 'intelligent', 'humor', '.']\n",
      "\n",
      "predicted class:           1\n"
     ]
    }
   ],
   "source": [
    "print (words)\n",
    "print (\"\\npredicted class:          \",   predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRP hyperparameters:\n",
    "eps                 = 0.001                                             # small positive number\n",
    "bias_factor         = 0.0                                               # recommended value\n",
    " \n",
    "net                 = LSTM_bidi()                                       # load trained LSTM model\n",
    "\n",
    "w_indices           = [net.voc.index(w) for w in words]                 # convert input sentence to word IDs\n",
    "Rx, Rx_rev, R_rest  = net.lrp(w_indices, target_class, eps, bias_factor)# perform LRP\n",
    "R_words             = np.sum(Rx + Rx_rev, axis=1)                       # compute word-level LRP relevances\n",
    "\n",
    "scores              = net.s.copy()                                      # classification prediction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction scores:         [ 8.90618621e-01  1.01122260e+00  2.26404237e-04 -3.12216870e-01\n",
      " -1.37174135e+00]\n",
      "\n",
      "LRP target class:          1\n",
      "\n",
      "LRP relevances:\n",
      "\t\t\t   -0.38\tthis\n",
      "\t\t\t   -0.41\tfilm\n",
      "\t\t\t   -0.03\tdoes\n",
      "\t\t\t    2.48\tn't\n",
      "\t\t\t   -0.16\tcare\n",
      "\t\t\t    0.10\tabout\n",
      "\t\t\t   -0.46\tcleverness\n",
      "\t\t\t   -0.06\t,\n",
      "\t\t\t   -0.45\twit\n",
      "\t\t\t    0.50\tor\n",
      "\t\t\t    0.10\tany\n",
      "\t\t\t    0.08\tother\n",
      "\t\t\t   -0.01\tkind\n",
      "\t\t\t    0.03\tof\n",
      "\t\t\t   -1.02\tintelligent\n",
      "\t\t\t   -1.14\thumor\n",
      "\t\t\t   -0.28\t.\n",
      "\n",
      "LRP heatmap:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#d8d8ff\">this</span> <span style=\"background-color:#d3d3ff\">film</span> <span style=\"background-color:#fcfcff\">does</span> <span style=\"background-color:#ff0000\">n't</span> <span style=\"background-color:#eeeeff\">care</span> <span style=\"background-color:#fff4f4\">about</span> <span style=\"background-color:#d0d0ff\">cleverness</span> <span style=\"background-color:#f8f8ff\">,</span> <span style=\"background-color:#d0d0ff\">wit</span> <span style=\"background-color:#ffcccc\">or</span> <span style=\"background-color:#fff4f4\">any</span> <span style=\"background-color:#fff6f6\">other</span> <span style=\"background-color:#fefeff\">kind</span> <span style=\"background-color:#fffcfc\">of</span> <span style=\"background-color:#9696ff\">intelligent</span> <span style=\"background-color:#8a8aff\">humor</span> <span style=\"background-color:#e2e2ff\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"prediction scores:        \",   scores)\n",
    "print (\"\\nLRP target class:         \", target_class)\n",
    "print (\"\\nLRP relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print (\"\\t\\t\\t\" + \"{:8.2f}\".format(R_words[idx]) + \"\\t\" + w)\n",
    "print (\"\\nLRP heatmap:\")    \n",
    "display(HTML(html_heatmap(words, R_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0112225974483908\n",
      "Sanity check passed?  True\n"
     ]
    }
   ],
   "source": [
    "# How to sanity check global relevance conservation:\n",
    "bias_factor        = 1.0                                             # value to use for sanity check\n",
    "Rx, Rx_rev, R_rest = net.lrp(w_indices, target_class, eps, bias_factor)\n",
    "R_tot              = Rx.sum() + Rx_rev.sum() + R_rest.sum()          # sum of all \"input\" relevances\n",
    "\n",
    "print(R_tot)       ;    print(\"Sanity check passed? \", np.allclose(R_tot, net.s[target_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net              = LSTM_bidi()                                       # load trained LSTM model\n",
    "\n",
    "w_indices        = [net.voc.index(w) for w in words]                 # convert input sentence to word IDs\n",
    "Gx, Gx_rev       = net.backward(w_indices, target_class)             # perform gradient backpropagation\n",
    "R_words_SA       = (np.linalg.norm(Gx + Gx_rev, ord=2, axis=1))**2   # compute word-level Sensitivity Analysis relevances\n",
    "R_words_GI       = ((Gx + Gx_rev)*net.x).sum(axis=1)                 # compute word-level GradientxInput relevances\n",
    "\n",
    "scores           = net.s.copy()                                      # classification prediction scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction scores:        [ 8.90618621e-01  1.01122260e+00  2.26404237e-04 -3.12216870e-01\n",
      " -1.37174135e+00]\n",
      "\n",
      "SA/GI target class:       1\n",
      "\n",
      "SA relevances:\n",
      "\t\t\t    0.32\tthis\n",
      "\t\t\t    0.07\tfilm\n",
      "\t\t\t    0.20\tdoes\n",
      "\t\t\t    2.08\tn't\n",
      "\t\t\t    0.93\tcare\n",
      "\t\t\t    0.03\tabout\n",
      "\t\t\t    0.24\tcleverness\n",
      "\t\t\t    0.08\t,\n",
      "\t\t\t    0.17\twit\n",
      "\t\t\t    0.20\tor\n",
      "\t\t\t    0.16\tany\n",
      "\t\t\t    0.06\tother\n",
      "\t\t\t    0.64\tkind\n",
      "\t\t\t    0.08\tof\n",
      "\t\t\t    1.39\tintelligent\n",
      "\t\t\t    0.77\thumor\n",
      "\t\t\t    0.11\t.\n",
      "\n",
      "SA heatmap:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#ffd8d8\">this</span> <span style=\"background-color:#fff6f6\">film</span> <span style=\"background-color:#ffe6e6\">does</span> <span style=\"background-color:#ff0000\">n't</span> <span style=\"background-color:#ff8c8c\">care</span> <span style=\"background-color:#fffcfc\">about</span> <span style=\"background-color:#ffe0e0\">cleverness</span> <span style=\"background-color:#fff4f4\">,</span> <span style=\"background-color:#ffeaea\">wit</span> <span style=\"background-color:#ffe6e6\">or</span> <span style=\"background-color:#ffecec\">any</span> <span style=\"background-color:#fff8f8\">other</span> <span style=\"background-color:#ffb0b0\">kind</span> <span style=\"background-color:#fff6f6\">of</span> <span style=\"background-color:#ff5454\">intelligent</span> <span style=\"background-color:#ffa0a0\">humor</span> <span style=\"background-color:#fff2f2\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GI relevances:\n",
      "\t\t\t    0.02\tthis\n",
      "\t\t\t   -0.04\tfilm\n",
      "\t\t\t    0.03\tdoes\n",
      "\t\t\t    0.20\tn't\n",
      "\t\t\t    0.54\tcare\n",
      "\t\t\t    0.23\tabout\n",
      "\t\t\t    0.04\tcleverness\n",
      "\t\t\t    0.18\t,\n",
      "\t\t\t   -0.00\twit\n",
      "\t\t\t    0.04\tor\n",
      "\t\t\t    0.00\tany\n",
      "\t\t\t    0.07\tother\n",
      "\t\t\t    0.09\tkind\n",
      "\t\t\t    0.24\tof\n",
      "\t\t\t   -0.40\tintelligent\n",
      "\t\t\t   -0.34\thumor\n",
      "\t\t\t    0.11\t.\n",
      "\n",
      "GI heatmap:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#fff6f6\">this</span> <span style=\"background-color:#eaeaff\">film</span> <span style=\"background-color:#fff2f2\">does</span> <span style=\"background-color:#ffa0a0\">n't</span> <span style=\"background-color:#ff0000\">care</span> <span style=\"background-color:#ff9292\">about</span> <span style=\"background-color:#ffeaea\">cleverness</span> <span style=\"background-color:#ffaaaa\">,</span> <span style=\"background-color:#fefeff\">wit</span> <span style=\"background-color:#ffecec\">or</span> <span style=\"background-color:#fffefe\">any</span> <span style=\"background-color:#ffe0e0\">other</span> <span style=\"background-color:#ffd6d6\">kind</span> <span style=\"background-color:#ff8e8e\">of</span> <span style=\"background-color:#4141ff\">intelligent</span> <span style=\"background-color:#5c5cff\">humor</span> <span style=\"background-color:#ffcaca\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"prediction scores:       \",   scores)\n",
    "print (\"\\nSA/GI target class:      \", target_class)\n",
    "print (\"\\nSA relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print (\"\\t\\t\\t\" + \"{:8.2f}\".format(R_words_SA[idx]) + \"\\t\" + w)\n",
    "print (\"\\nSA heatmap:\")    \n",
    "display(HTML(html_heatmap(words, R_words_SA)))\n",
    "print (\"\\nGI relevances:\")\n",
    "for idx, w in enumerate(words):\n",
    "    print (\"\\t\\t\\t\" + \"{:8.2f}\".format(R_words_GI[idx]) + \"\\t\" + w)\n",
    "print (\"\\nGI heatmap:\")    \n",
    "display(HTML(html_heatmap(words, R_words_GI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Recursive Neural Tensor Network\n",
    "# prediction scores:  [ 8.90618621e-01  1.01122260e+00  2.26404237e-04 -3.12216870e-01 -1.37174135e+00]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
