{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22dc3d6-0c9e-49f7-8f3f-83f8c0458e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import imp\n",
    "import keras.backend\n",
    "import keras.models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "from matplotlib import cm, transforms\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "import innvestigate.applications.mnist\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.utils.tests.networks import base as network_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c99536-e9f1-4adf-ae39-ebf79d8dc5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  stanfordSentimentTreebank.zip\n",
      "   creating: stanfordSentimentTreebank/\n",
      "  inflating: stanfordSentimentTreebank/datasetSentences.txt  \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/stanfordSentimentTreebank/\n",
      "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSentences.txt  \n",
      "  inflating: stanfordSentimentTreebank/datasetSplit.txt  \n",
      "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSplit.txt  \n",
      "  inflating: stanfordSentimentTreebank/dictionary.txt  \n",
      "  inflating: __MACOSX/stanfordSentimentTreebank/._dictionary.txt  \n",
      "  inflating: stanfordSentimentTreebank/original_rt_snippets.txt  \n",
      "  inflating: __MACOSX/stanfordSentimentTreebank/._original_rt_snippets.txt  \n",
      "  inflating: stanfordSentimentTreebank/README.txt  \n",
      "  inflating: __MACOSX/stanfordSentimentTreebank/._README.txt  \n",
      "  inflating: stanfordSentimentTreebank/sentiment_labels.txt  \n",
      "  inflating: __MACOSX/stanfordSentimentTreebank/._sentiment_labels.txt  \n",
      "  inflating: stanfordSentimentTreebank/SOStr.txt  \n",
      "  inflating: stanfordSentimentTreebank/STree.txt  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0   329    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 6223k  100 6223k    0     0   975k      0  0:00:06  0:00:06 --:--:-- 1452k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ ! -d \"./stanfordSentimentTreebank\" ]; then\n",
    "    curl -L http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip -O && unzip stanfordSentimentTreebank.zip\n",
    "else\n",
    "    echo \"The data is already there. Skip downloading!!\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b71d71c-9385-41f7-937d-7c51458a693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   147  100   147    0     0    350      0 --:--:-- --:--:-- --:--:--   350\n",
      "100 9158k  100 9158k    0     0  5176k      0  0:00:01  0:00:01 --:--:-- 11.2M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   138  100   138    0     0    542      0 --:--:-- --:--:-- --:--:--   545\n",
      "100  207k  100  207k    0     0   430k      0 --:--:-- --:--:-- --:--:-- 8235k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ ! -e \"./stanfordSentimentTreebank/embeddings.npy\" ]; then\n",
    "    curl -L https://github.com/ArrasL/LRP_for_LSTM/raw/master/model/embeddings.npy -o stanfordSentimentTreebank/embeddings.npy &&\n",
    "        curl -L https://github.com/ArrasL/LRP_for_LSTM/raw/master/model/vocab -o stanfordSentimentTreebank/vocab\n",
    "else\n",
    "    echo \"The data is already there. Skip downloading!!\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffa540e-e130-40ae-ac59-091affe8acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ftfy in c:\\program files\\python36\\lib\\site-packages (6.0.3)\n",
      "Requirement already satisfied: wcwidth in c:\\program files\\python36\\lib\\site-packages (from ftfy) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a972a5-0d5e-45bb-8fd6-7562eaea659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d66167-35ae-451a-af06-daa5ad58ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './stanfordSentimentTreebank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d9288e-6ad9-4a05-8f20-c68bfd832181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 19539 vocabs.\n"
     ]
    }
   ],
   "source": [
    "with open('%s/vocab' % DATA_PATH, 'rb') as f:\n",
    "    vocabs = pickle.load(f) \n",
    "    total_vocabs = len(vocabs) \n",
    "\n",
    "    # Unknown vocabs are set to <UNK>.\n",
    "    encoder = dict(zip(['<UNK>'] + vocabs, range(0, len(vocabs) +1)))\n",
    "    decoder = dict(zip(encoder.values(), encoder.keys()))\n",
    "    \n",
    "    print('We have %d vocabs.' % len(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5f63eb-25fa-40b4-af2a-59248106442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = np.load('%s/embeddings.npy' % DATA_PATH)\n",
    "\n",
    "# Unknown vocabs will have embedding weights of zero.\n",
    "embedding = np.zeros((pretrained_embedding.shape[0]+1, pretrained_embedding.shape[1]))\n",
    "embedding[1:, :] = pretrained_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4acecb4c-2429-43f6-b765-5ffb7ddd6dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>phase</th>\n",
       "      <th>sostr</th>\n",
       "      <th>splitset_label</th>\n",
       "      <th>phase_id</th>\n",
       "      <th>sentiment_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>The|Rock|is|destined|to|be|the|21st|Century|'s...</td>\n",
       "      <td>1</td>\n",
       "      <td>226166</td>\n",
       "      <td>0.69444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>The|gorgeously|elaborate|continuation|of|``|Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>226300</td>\n",
       "      <td>0.83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>Effective|but|too-tepid|biopic</td>\n",
       "      <td>2</td>\n",
       "      <td>13995</td>\n",
       "      <td>0.51389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>If|you|sometimes|like|to|go|to|the|movies|to|h...</td>\n",
       "      <td>2</td>\n",
       "      <td>14123</td>\n",
       "      <td>0.73611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>Emerges|as|something|rare|,|an|issue|movie|tha...</td>\n",
       "      <td>2</td>\n",
       "      <td>13999</td>\n",
       "      <td>0.86111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_index                                           sentence  \\\n",
       "0               1  The Rock is destined to be the 21st Century 's...   \n",
       "1               2  The gorgeously elaborate continuation of `` Th...   \n",
       "2               3                     Effective but too-tepid biopic   \n",
       "3               4  If you sometimes like to go to the movies to h...   \n",
       "4               5  Emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                               phase  \\\n",
       "0  The Rock is destined to be the 21st Century 's...   \n",
       "1  The gorgeously elaborate continuation of `` Th...   \n",
       "2                     Effective but too-tepid biopic   \n",
       "3  If you sometimes like to go to the movies to h...   \n",
       "4  Emerges as something rare , an issue movie tha...   \n",
       "\n",
       "                                               sostr  splitset_label  \\\n",
       "0  The|Rock|is|destined|to|be|the|21st|Century|'s...               1   \n",
       "1  The|gorgeously|elaborate|continuation|of|``|Th...               1   \n",
       "2                     Effective|but|too-tepid|biopic               2   \n",
       "3  If|you|sometimes|like|to|go|to|the|movies|to|h...               2   \n",
       "4  Emerges|as|something|rare|,|an|issue|movie|tha...               2   \n",
       "\n",
       "   phase_id  sentiment_value  \n",
       "0    226166          0.69444  \n",
       "1    226300          0.83333  \n",
       "2     13995          0.51389  \n",
       "3     14123          0.73611  \n",
       "4     13999          0.86111  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all necessary files\n",
    "df_reviews = pd.read_csv('%s/datasetSentences.txt' % DATA_PATH, sep='\\t')\n",
    "\n",
    "df_reviews['phase'] = df_reviews.sentence.apply(lambda s: fix_encoding(s))\\\n",
    "    .apply(lambda s: s.replace('-LRB-', '(').replace('-RRB-', ')'))\n",
    "\n",
    "df_reviews['sostr'] = pd.read_csv('%s/SOStr.txt' % DATA_PATH,\n",
    "                                  sep='\\t',encoding='utf-8',\n",
    "                                  header=None, names=['sostr']\n",
    "                                 )\n",
    "\n",
    "df_reviews['splitset_label'] = pd.read_csv('%s/datasetSplit.txt' % DATA_PATH,\n",
    "                                           sep=',', header=0\n",
    "                                          )['splitset_label']\n",
    "\n",
    "\n",
    "df_phases = pd.read_csv('%s/dictionary.txt' % DATA_PATH,\n",
    "                        sep='|', names=['phase', 'phase_id']\n",
    "                       )\n",
    "\n",
    "df_sentiment_labels = pd.read_csv('%s/sentiment_labels.txt' % DATA_PATH,\n",
    "                                  sep='|', names=['phase_id', 'sentiment_value'],\n",
    "                                  header=0\n",
    "                                 )\n",
    "\n",
    "df_reviews_with_sentiment_value = df_reviews.merge(df_phases, how='inner', on=['phase'])\\\n",
    "    .merge(df_sentiment_labels, on='phase_id')\n",
    "\n",
    "df_reviews_with_sentiment_value[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f3060-4311-4430-a383-1e1ed509c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_discretizer(sentiment_value):\n",
    "    if 0 <= sentiment_value <= 0.2:\n",
    "        return 'very_negative'\n",
    "    elif 0.2 < sentiment_value <= 0.4:\n",
    "        return 'negative'\n",
    "    elif 0.4 < sentiment_value <= 0.6:\n",
    "        return 'neutral'\n",
    "    elif 0.6 < sentiment_value <= 0.8:\n",
    "        return 'positive'\n",
    "    elif 0.8 < sentiment_value <= 1:\n",
    "        return 'very_positive'\n",
    "    \n",
    "df_reviews_with_sentiment_value['label'] = df_reviews_with_sentiment_value.sentiment_value.apply(sentiment_discretizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
